---
title: "Applying Multivariate Techniques to Magnetic Resonance Imaging Scans of Individuals With and Without Alzheimers"
author: "Michael Seebregts"
date: "7 April 2025"
output:
  pdf_document: default
  word_document: default
  
header-includes: 
  - \usepackage{float}
  - \usepackage{booktabs}
  - \usepackage{placeins}
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, 
                      warning = FALSE, 
                      message = FALSE,
                      fig.device = "png")

library(magick)
library(EBImage)
library(stringr)
library(dplyr)
library(stringr)
library(knitr)
library(curl)
library(kableExtra)
library(cowplot)
library(ggpubr)
library(dbscan)
library(plotly)
library(ggplot2)
library(reticulate)
use_condaenv("py310", required = TRUE)
library(tensorflow)
library(keras)
library(lle)
 set.seed(56)
 
 tensorflow::tf$random$set_seed(56)
 Sys.setenv("TF_DETERMINISTIC_OPS" = "1")  # These 2 ensure that the autoencoder and Convolutional autoencoder are reproducible. 

while (dev.cur() > 1) dev.off()

Sys.setenv(TF_CPP_MIN_LOG_LEVEL = "3")

```
# 1: Introduction

Alzheimers Disease is a type of brain disease that is characterized by damage to the neurons in the brain, particularly those in the hippocampus which is responsible for thinking, talking and walking (Alzheimer’s Association, 2024). Alzheimers is believed to begin over 20 years before the symptoms appear. As the disease progresses, there are significant changes to the brain. These changes include the accumulation of the protein beta- amyloid outside neurons, twisted strands of protein tau inside neurons, as well as inflammation and atrophy of brain tissue (Alzheimer’s Association, 2024).

Alzheimer’s disease accounts for an estimated 60% - 80% of all dementia cases. It occurs more often in people 65 and over (Alzheimer’s Association, 2024). The US census bureau estimated that 910,000 people aged 65 or older developed Alzheimer’s in 2011 in the US with an incidence rate of 0.4% for people aged 65-74, 3.2% for people aged 75 - 84 and 7.6% for people aged 86 and older. These incidence rates are projected to double by 2050, due to the increasing number of people aged 65 and over in the US (Alzheimer’s Association, 2024). Women are affected more by Alzheimers disease than men as they live longer, with almost two-thirds of Americans with Alzheimers being women. Age is one of the greatest risk factors for Alzheimers. Studies have found that Alzheimers does not affect women more than men but the higher prevalence is due to women living longer than men (Alzheimer’s Association, 2024).

With Alzheimers being so prevalent, being able to accurately predict early signs of Alzheimer’s will allow early prevention steps to be taken in order to potentially slow or stop the progression of the disease.

Structural Magnetic Image Resonance (MRI) markers are a part of the clinical assessment in order to determine if someone has Alzheimer’s (Frisoni GB, et al, 2010). These MRI markers provide healthcare workers with more accurate and precise diagnosis, and allow for the progression of Alzheimers to be measured. According to current research, particularly powerful markers are the rates of whole brain and hippocampal atrophy (Frisoni GB, et al, 2010).

This paper explores whether multivariate techniques can be applied to MRI Scans of individuals brains in order to effectively predict Alzheimers. Based on the current research and information, the inflammation and atrophy of brain tissue may be recognisable by a sufficiently informed model.

# 2: Data Description

The data set consists of 400 observations with 9 predictors along with the 3 brain scans and 1 predictor, being clinical dementia rating. The patient information is as follows: 

1. SESSION ID
2. AGE - age of patients
3. M/F - whether patient is male or female
4. HAND - dominant hand of the patient, in this case all patients are right handed
5. EDUC - education level of the patient, education level ranges from 1, no formal education, to 5 being a graduate or professional degree
6. SES - socio-economic status of the patient, SES ranges from 1, very low socioeconomic status, to 5, very high socioeconomic status
7. CDR - clinical dementia rating of the patient, the CDR scores have a range of 0, no dementia, 0.5, mild dementia, 1, moderate dementia and 2, severe dementia 
8. MMSE - mini mental state examination (test scoring their memory, attention and problem solving). A MMSE score of 0-17 indicates severe cognitive impairment while 28 - 30 indicates normal cognitive function. 
9. eTIV - estimated total volume of the skull 
10. ASF - factor used to normalize brain measurements 
11. nWBV - total brain volume, normalized for intracranial volume 
The brain scans themselves have been normalized already so that brain scans for the front all have the same pixels, with the same being done for the side and top scans.

This data was collected with each subject being aged between 18 - 96. For each subject, 3 or 4 individual T1-weighted MRI scans were obtained in a single scan session. All the subjects were right handed and are a mixture of men and women. The data is currently hosted on WashU Medicine, titled OASIS1 Dataset (Marus, et al, 2010).  

# 3: Analysis Approach

The response variable is the CDR rating which will either be 0, 0.5, 1 or 2. The main predictor will be the MRI scans of the individuals. The MRI scans for the 58th observation is: 

```{r mri, echo = FALSE, fig.show = "hold", fig.align = "center", out.height="30%", out.width="30%", fig.cap = "Front, Side and Top MRI Scans for Patient 58"}

knitr::include_graphics(c("F:/.University/5th Year/STA5069Z/SBRMIC008_STA5069Z_Project/Images/OAS1_0058_MR1_mpr_n4_anon_111_t88_gfc_cor_110.jpg", "F:/.University/5th Year/STA5069Z/SBRMIC008_STA5069Z_Project/Images/OAS1_0058_MR1_mpr_n4_anon_111_t88_gfc_sag_95.jpg", "F:/.University/5th Year/STA5069Z/SBRMIC008_STA5069Z_Project/Images/OAS1_0058_MR1_mpr_n4_anon_111_t88_gfc_tra_90.jpg"))
```

Each individual has these same 3 MRI scans (Marus, et al, 2010).

```{r readFiles, echo = FALSE, eval = FALSE}
# Install BiocManager to install EBImage
#install.packages("BiocManager", dependencies = TRUE)
# Use BiocManager to install EBImage
#BiocManager::install("EBImage")

# Following code was used to read in all the images, convert them into their pixels
# These matrices of pixels were normalised and saved to a list denoting if they are top, front, side
# This list was written to files in order to not have to read in the raw images everytime. 

# listOfPixels = list()
# 
# main = "F:/.University/5th Year/STA5069Z/SBRMIC008_STA5069Z_Project/Data/Oasis/"
# 
# file_names = list.files(main, full.names = TRUE)
# 
# numID = c()
# 
# patientInfo = data.frame(c())
# 
# extract = function(input)
# {
#   inputTemp = gsub(" ", "", input)
#   colonPos = str_locate(inputTemp, ":")
#   afterColon = substr(inputTemp, colonPos[1] + 1, nchar(inputTemp))
# 
#   return (afterColon)
# }
# 
# len = length(file_names)
# 
# listOfFiles = data.frame("Front" = character(len), "Side" = character(len), "Top" = character(len))
# 
# for (i in 1:len)
# {
#   numID = c(numID, (str_extract(file_names[i], "(?<=OAS1_)\\d{4}")))
#   sub = paste(file_names[i],"/PROCESSED/MPRAGE/T88_111", sep = "")
# 
#   textFile = readLines(paste0(file_names[i],"/OAS1_",numID[i],"_MR1.txt"))
# 
#   age_line = textFile[2]
#   gender_line = textFile[3]
#   educ_line = textFile[5]
#   ses_line = textFile[6]
#   cdr_line = textFile[7]
#   mmse_line = textFile[8]
#   etiv_line = textFile[10]
#   asf_line = textFile[11]
#   nwbv_line = textFile[12]
# 
#   age = as.numeric(extract(age_line))
#   gender = extract(gender_line)
#   educ = extract(educ_line)
#   ses = extract(ses_line)
#   cdr = extract(cdr_line)
#   mmse = as.numeric(extract(mmse_line))
#   etiv = as.numeric(extract(etiv_line))
#   asf = as.numeric(extract(asf_line))
#   nwbv = as.numeric(extract(nwbv_line))
# 
#   tempInfo = c(age, gender, educ, ses, cdr, mmse, etiv, asf, nwbv)
# 
#   patientInfo = rbind(patientInfo, tempInfo)
#   
#   tempObs = c()
# 
#   front = paste(sub,"/OAS1_",numID[i],"_MR1_mpr_n4_anon_111_t88_gfc_cor_110.gif", sep = "")
#   front2 = paste(sub,"/OAS1_",numID[i],"_MR1_mpr_n3_anon_111_t88_gfc_cor_110.gif", sep = "")
#   front3 = paste(sub,"/OAS1_",numID[i],"_MR1_mpr_n6_anon_111_t88_gfc_cor_110.gif", sep = "")
#   front4 = paste(sub,"/OAS1_",numID[i],"_MR1_mpr_n5_anon_111_t88_gfc_cor_110.gif", sep = "")
#   
#   print(listOfFiles[nrow(listOfFiles), 1])
#   
#   if (file.exists(front))
#   {
#     side = paste(sub,"/OAS1_",numID[i],"_MR1_mpr_n4_anon_111_t88_gfc_sag_95.gif", sep = "")
#     top = paste(sub,"/OAS1_",numID[i],"_MR1_mpr_n4_anon_111_t88_gfc_tra_90.gif", sep = "")
#     tempObs = c(front, side, top)
#     listOfFiles[i, ] = tempObs
# 
#   }
# 
#   if (file.exists(front2))
#   {
#     side = paste(sub,"/OAS1_",numID[i],"_MR1_mpr_n3_anon_111_t88_gfc_sag_95.gif", sep = "")
#     top = paste(sub,"/OAS1_",numID[i],"_MR1_mpr_n3_anon_111_t88_gfc_tra_90.gif", sep = "")
#     tempObs = c(front2, side, top)
#     listOfFiles[i, ] = tempObs
# 
#   }
# 
#   if (file.exists(front3))
#   {
#     side = paste(sub,"/OAS1_",numID[i],"_MR1_mpr_n6_anon_111_t88_gfc_sag_95.gif", sep = "")
#     top = paste(sub,"/OAS1_",numID[i],"_MR1_mpr_n6_anon_111_t88_gfc_tra_90.gif", sep = "")
#     tempObs = c(front3, side, top)
#     listOfFiles[i, ] = tempObs
# 
#   }
#   
#   if (file.exists(front4))
#   {
#     side = paste(sub,"/OAS1_",numID[i],"_MR1_mpr_n5_anon_111_t88_gfc_sag_95.gif", sep = "")
#     top = paste(sub,"/OAS1_",numID[i],"_MR1_mpr_n5_anon_111_t88_gfc_tra_90.gif", sep = "")
#     tempObs = c(front4, side, top)
#     listOfFiles[i, ] = tempObs
#     
#   }
# 
# 
# }
# image_list = list()
# 
# for (j in 1:dim(listOfFiles)[1])
# {
#   imgFront = image_read(listOfFiles[j, 1])
#   imgFront = image_convert(imgFront, colorspace = "gray")
#   imgFront_dat = image_data(imgFront)
# 
#   imgSide = image_read(listOfFiles[j, 2])
#   imgSide = image_convert(imgSide, colorspace = "gray")
#   imgSide_dat = image_data(imgSide)
# 
#   imgTop = image_read(listOfFiles[j, 3])
#   imgTop = image_convert(imgTop, colorspace = "gray")
#   imgTop_dat = image_data(imgTop)
# 
# 
#   heightFront = dim(imgFront_dat)[3]
#   widthFront = dim(imgFront_dat)[2]
# 
#   heightSide = dim(imgSide_dat)[3]
#   widthSide = dim(imgSide_dat)[2]
# 
#   heightTop = dim(imgTop_dat)[3]
#   widthTop = dim(imgTop_dat)[2]
# 
#   full_imgFront_dat = matrix(as.numeric(imgFront_dat[,,1]), ncol = 1, byrow = TRUE)
#   full_imgSide_dat = matrix(as.numeric(imgSide_dat[,,1]), ncol = 1, byrow = TRUE)
#   full_imgTop_dat = matrix(as.numeric(imgTop_dat[,,1]), ncol = 1, byrow = TRUE)
# 
# 
#   for (q in 2:heightFront)
#   {
#     full_imgFront_dat = cbind(full_imgFront_dat, as.numeric(imgFront_dat[,,q]))
#   }
# 
#   for (z in 2:heightSide)
#   {
#     full_imgSide_dat = cbind(full_imgSide_dat, as.numeric(imgSide_dat[,,z]))
# 
#   }
# 
#   for (g in 2:heightTop)
#   {
# 
#     full_imgTop_dat = cbind(full_imgTop_dat, as.numeric(imgTop_dat[,,g]))
#   }
# 
#   norm_full_imgFront_dat = full_imgFront_dat/max(full_imgFront_dat)
#   norm_full_imgSide_dat = full_imgSide_dat/max(full_imgSide_dat)
#   norm_full_imgTop_dat = full_imgTop_dat/max(full_imgTop_dat)
# 
#   id = sprintf("%04d", j)
# 
#   listOfPixels[[paste0("image_",id,"_front")]] = norm_full_imgFront_dat
#   listOfPixels[[paste0("image_",id,"_side")]] = norm_full_imgSide_dat
#   listOfPixels[[paste0("image_",id,"_top")]] = norm_full_imgTop_dat
# }
# 
# saveRDS(listOfPixels, "pixelsMatrix")
# 
# colnames(patientInfo) = c("age", "gender", "educ", "ses", "cdr", "mmse", "etiv", "asf", "nwbv")
# 
# write.csv(patientInfo, file = "F:/.University/5th Year/STA5069Z/SBRMIC008_STA5069Z_Project/PatientInfo.csv")
```

```{r eda, echo = FALSE}

pixelsMatrixRaw = readRDS("F:/.University/5th Year/STA5069Z/SBRMIC008_STA5069Z_Project/pixelsMatrix")
patientInfoRaw = read.csv("F:/.University/5th Year/STA5069Z/SBRMIC008_STA5069Z_Project/PatientInfo.csv")

missingCDR = sum(is.na(patientInfoRaw$cdr))

remainingObs = length(patientInfoRaw$cdr) - missingCDR

noNA = patientInfoRaw %>% filter(!is.na(cdr))

cdr0 = length(noNA$cdr[noNA$cdr == 0])
cdr05 = length(noNA$cdr[noNA$cdr == 0.5])
cdr1 = length(noNA$cdr[noNA$cdr == 1])
cdr2 = length(noNA$cdr[noNA$cdr == 2])


cdrDataFrame = data.frame("CDR = NA" = missingCDR, "CDR = 0" = cdr0, "CDR = 0.5" = cdr05, "CDR = 1" = cdr1, "CDR = 2" = cdr2)

kable(cdrDataFrame, caption = "Table of number of indiviuals with different levels of CDR", col.names = c("CDR = NA", "CDR = 0", "CDR = 0.5", "CDR = 1", "CDR = 2") )%>%
  kable_styling(position = "center")
```

We can see that 176 of the patients do not have a CDR rating. These observations will need to be thrown out, leaving 224 observations. 

For a CDR level of 2, there are only 2 observations in this category. This lack of data may not allow a model to effectively predict this level. CDR level of 2 will be therefore be combined with CDR level of 1.

```{r eda2, echo = FALSE}
prob0 = cdr0/remainingObs
prob05 = cdr05/remainingObs
prob1 = (cdr1+cdr2)/remainingObs


cdrProbDF = data.frame("CDR 0" = prob0, "CDR 0.5" = prob05, "CDR 1" = prob1)

kable(cdrProbDF, caption = "Table of the probability of indiviuals having different levels of CDR", col.names = c("CDR = 0", "CDR = 0.5", "CDR = 1"))%>%
  kable_styling(position = "center")
```

Can see that around 60% of observations have no Alzheimers, 30% have mild Alzheimers and 10% have moderate Alzheimers. 

# 4: Methodology

The goal of this paper is to identify patterns in brain scans that correlate with the 3 different CDR scores. To this extent, dimensionality reduction techniques will be used, along with clustering methods and convolutional neural networks, in order to extract information from the MRI scans. 
Due to the focus being on feature extraction and MRI scans being in black and white, the images were grey scaled in order to reduce the complexity of the data. Greyscaling was done via the Magick package in R and converted into pixel values. These pixel values were normalised to be between 0 and 1, with 1 being white, 0 being black and any number in between being the amount of white contained in the pixel. 

The OASIS1 Dataset uploads their images in a normalized format already and so the images did not require any extra normalization and could be converted into a single vector of pixel values. All front scans have size 176x176, all side scans have size 176x208 and all top scans have size 208x176.

## 4.1: Dimension Reduction

Locally Linear Embedding (LLE) was applied in order to retain the most important information. LLE is effective at maintaining the local structure of the data so that points in the high dimensional space remain close in the lower dimensional embedding. This is important for MRI scans in order to keep the local structure of the brain in the lower dimension. LLE also allows for non linear relationships and so can capture the more complex patterns inside the brian. The issues with LLE is that it does not keep the global structure of the brain  which can be problematic as we try and investigate the differences in the entire brain of an individual. LLE is also very impacted by the choice of neighborhood size which can lead to noise being introduced or not capturing the underlying trends. 

The use of autoencoders was investigated as well since autoencoders are also capable of nonlinear dimension reduction which should be able to capture more meaningful representations in the data. Autoencoders are especially useful for anomaly detection as the reconstruction error will be high if there is an anomaly in the scan. Auto encoders offer a lot of flexibility in the model design and can then be tailored to the MRI scans. However, auto encoders are prone to overfitting if the network architecture is too complex, but may also not capture sufficient variability in the scans if it isnt sufficiently complex. Auto encoders also have larger data requirements in order to fit the model. 2 Auto Encoders were used, both with 5 hidden layers, with the number of nodes being 2056, 1024 and 128 in the bottleneck. The first auto encoder used linear activation functions for the 2056 nodes and sigmoid for the rest. The second auto encoder used Relu for all layers. These 2 activation functions were used on the front, top and side scans separately. 

## 4.2: Clustering

After applying the dimension reduction, K-Means was applied to the reduced dimensions in order to see if the clusters will be able to group the various CDR levels. K-means has been used in many MRI scans due to the the speed and ability for it to differentiate brain tissue and diagnose neurodegenerative diseases. K means does have the disadvantage of having to define the number of clusters beforehand, but 2 clusters for CDR = 0 or CDR > 0 or 3 clusters for CDR = 0, CDR = 0.5 and CDR = 1 seems like likely candidates. K-means also struggles to capture spatial information which can lead to segmentation errors as well as struggles to deal with non-spherical shaped clusters. 

Density based clustering was used as well, particularly DBScan. DBScan is able to detect arbitrary shaped clusters, doesnt need to predefine the number of clusters and can detect dense regions in the brain scans, such as gray matter in the brain or tumors. DBScan is however highly sensitive to the epsilon and minimum points chosen and assumes that clusters have similar density, which may not always be the case due to varying regions of the brain. Thus DBScan was used as well to cluster the reduced dimensions. 

## 4.3: Convolutional Neural Network

In order to compare results, a convolutional neural network (CNN) was used as well in order to classify the MRI scans. The convolutional model used was a branched approach which had a 93% accuracy when using 3 branches with 3x3, 5x5 and 7x7 sized filters but had up to 128 filters for the second and third branch with more convolutional layers in each branch (Mandal, Mahato. 2023.). In order to apply this, 3 branches were used with the first branch using 3x3 filter, the second a 5x5 filter and the third a 7x7 filter. These branches were then combined and fed into a fully connected 128 node layer and then to a 64 node layer before outputing the predictions in a 3 node layer. Relu was used throughout for activation functions and softmax on the output layer. 

```{r LLE, echo = FALSE, fig.height=4, fig.width=4, results='asis', include = FALSE, eval = TRUE}

 
obsNotNA = which(!is.na(patientInfoRaw$cdr))

patientInfo = patientInfoRaw[obsNotNA, ]

imagesWithNACDR = sprintf("%04d", obsNotNA)

# Removing 2 cdr and grouping it with 1 cdr
patientInfo$cdr[patientInfo$cdr == 2] = 1


front = paste0("image_",imagesWithNACDR, "_front")
top = paste0("image_",imagesWithNACDR, "_top")
side = paste0("image_",imagesWithNACDR, "_side")

pixelsMatrix = list()

for (i in 1:length(obsNotNA))
{
  tempFront = front[i]
  tempTop = top[i]
  tempSide = side[i]
  
  pixelsMatrix[[tempFront]] = pixelsMatrixRaw[[tempFront]]
  pixelsMatrix[[tempSide]] = pixelsMatrixRaw[[tempSide]]
  pixelsMatrix[[tempTop]] = pixelsMatrixRaw[[tempTop]]
  
}

flatPixels = lapply(pixelsMatrix, c)

flatFront = matrix(flatPixels[["image_0001_front"]], nrow = 1)
flatTop = matrix(flatPixels[["image_0001_top"]], nrow = 1)
flatSide = matrix(flatPixels[["image_0001_side"]], nrow = 1)


for (j in 2:length(obsNotNA))
{
  
  flatFront = rbind(flatFront, t(flatPixels[[front[j]]]))
  flatTop = rbind(flatTop, t(flatPixels[[top[j]]]))
  flatSide = rbind(flatSide, t(flatPixels[[side[j]]]))
}

frontDF = data.frame(flatFront, cdr = as.factor(patientInfo$cdr))
topDF = data.frame(flatTop, cdr = as.factor(patientInfo$cdr))
sideDF = data.frame(flatSide, cdr = as.factor(patientInfo$cdr))

# LLE Front Scans

frontPCA = prcomp(flatFront, center = TRUE, scale = FALSE)
cumulativeVarianceFront = cumsum(summary(frontPCA)$importance[2, ])

png("frontPCA.png")
plot(cumulativeVarianceFront, main = "Cumulative variance plot for different Principal Components on Front MRI Scans", cex.main = 0.8)
dev.off()

invisible(capture.output(
  lleResult <- lle(X = flatFront, m = 80, k = 30)
))
lleComp = lleResult$Y

kmeansLLE = kmeans(lleComp, centers = 3)
dfLLE = data.frame("Clusters" = kmeansLLE$cluster-1, "CDR" = patientInfo$cdr)
kmeans3LLE = kable(table(dfLLE), format = "latex", 
                   col.names = c("Cluster","CDR = 0", "CDR = 0.5", "CDR = 1"),
                   booktabs = TRUE)

kmeansLLE2 = kmeans(lleComp, centers = 2)
dfLLE2 = data.frame("Clusters" = kmeansLLE2$cluster-1, "CDR" = patientInfo$cdr)
kmeans2LLE = kable(table(dfLLE2), format = "latex", 
                   col.names = c("Cluster","CDR = 0", "CDR = 0.5", "CDR = 1"), 
                   booktabs = TRUE)

optLLE = optics(lleComp, minPts = 50)
png("LLEReachability.png")
plot(optLLE, main = "Reachbility plot for LLE DBScan", cex.main = 0.8)
dev.off()

dbscanLLE = extractDBSCAN(optLLE, eps_cl = 10)
LLEDBScanDF = data.frame("Clusters" = dbscanLLE$cluster, "CDR" = patientInfo$cdr)
DBScanLLE = kable(table(LLEDBScanDF), format = "latex", 
                   col.names = c("Cluster", "CDR = 0", "CDR = 0.5", "CDR = 1"),
                   booktabs = TRUE)

LLETable = c(
  "\\begin{table}[h] \\centering",
  "\\begin{minipage}{0.3\\textwidth}",
  kmeans3LLE,        # KMeans Clustering with 3 Clusters
  "\\caption{K-Means Clustering with 3 Clusters for LLE on Front MRI Scans}",
  "\\end{minipage}",
  "\\hspace{3cm}",    # Space between tables
  "\\begin{minipage}{0.3\\textwidth}",
  kmeans2LLE,        # KMeans Clustering with 2 Clusters
  "\\caption{K-Means Clustering with 2 Clusters for LLE on Front MRI Scans}",
  "\\end{minipage}",
  "\\hspace{3cm}",    # Space between tables
  "\\begin{minipage}{0.3\\textwidth}",
  DBScanLLE,        # DBScan Clustering
  "\\caption{DBScan Clustering for LLE on Front MRI Scans}",
  "\\end{minipage}",
  "\\end{table}"
)

writeLines(LLETable, "LLE_Front_clustering_tables.tex")
```

```{r lleTop, echo = FALSE, fig.height=4, fig.width=4, results='asis', include = FALSE, eval = TRUE}
# LLE Top Scans
 
topPCA = prcomp(flatTop, center = TRUE, scale = FALSE)
cumulativeVarianceTop = cumsum(summary(topPCA)$importance[2, ])


png("topPCA.png")
plot(cumulativeVarianceTop, main = "Cumulative variance plot for different Principal Components on Top MRI Scans", cex.main = 0.8)
dev.off()



invisible(capture.output(
  lleResultTop <- lle(X = flatTop, m = 80, k = 30)
))
lleCompTop = lleResultTop$Y

kmeansLLETop3 = kmeans(lleCompTop, centers = 3)
dfLLE3Top = data.frame("Clusters" = kmeansLLETop3$cluster-1, "CDR" = patientInfo$cdr)
kmeansTop3LLE = kable(table(dfLLE3Top), format = "latex", 
                   col.names = c("Cluster","CDR = 0", "CDR = 0.5", "CDR = 1"),
                   booktabs = TRUE)

kmeansLLETop2 = kmeans(lleCompTop, centers = 2)
dfLLETop2 = data.frame("Clusters" = kmeansLLETop2$cluster-1, "CDR" = patientInfo$cdr)
kmeansTop2LLE = kable(table(dfLLETop2), format = "latex", 
                   col.names = c("Cluster","CDR = 0", "CDR = 0.5", "CDR = 1"), 
                   booktabs = TRUE)

optLLETop = optics(lleCompTop, minPts = 50)
png("LLETopReachability.png")
plot(optLLETop, main = "Reachbility plot for LLE DBScan", cex.main = 0.8)
dev.off()

dbscanLLETop = extractDBSCAN(optLLETop, eps_cl = 10.4)
LLEDBScanDFTop = data.frame("Clusters" = dbscanLLETop$cluster, "CDR" = patientInfo$cdr)
DBScanLLETop = kable(table(LLEDBScanDFTop), format = "latex", 
                   col.names = c("Cluster", "CDR = 0", "CDR = 0.5", "CDR = 1"),
                   booktabs = TRUE)

LLETableTop = c(
  "\\begin{table}[h] \\centering",
  "\\begin{minipage}{0.3\\textwidth}",
  kmeansTop3LLE,        # KMeans Clustering with 3 Clusters
  "\\caption{K-Means Clustering with 3 Clusters for LLE on Top MRI Scans}",
  "\\end{minipage}",
  "\\hspace{3cm}",    # Space between tables
  "\\begin{minipage}{0.3\\textwidth}",
  kmeansTop2LLE,        # KMeans Clustering with 2 Clusters
  "\\caption{K-Means Clustering with 2 Clusters for LLE on Top MRI Scans}",
  "\\end{minipage}",
  "\\hspace{3cm}",    # Space between tables
  "\\begin{minipage}{0.3\\textwidth}",
  DBScanLLETop,        # DBScan Clustering
  "\\caption{DBScan Clustering for LLE on Top MRI Scans}",
  "\\end{minipage}",
  "\\end{table}"
)

writeLines(LLETableTop, "LLE_Top_clustering_tables.tex")
```

```{r lleSide, echo = FALSE, fig.height=4, fig.width=4, results='asis', include = FALSE, eval = TRUE}
# LLE Side Scans
 
sidePCA = prcomp(flatSide, center = TRUE, scale = FALSE)
cumulativeVarianceSide = cumsum(summary(sidePCA)$importance[2, ])

png("sidePCA.png")
plot(cumulativeVarianceSide, main = "Cumulative variance plot for different Principal Components on Side MRI Scans", cex.main = 0.8)
dev.off()

invisible(capture.output(
  lleSideResult <- lle(X = flatSide, m = 80, k = 30)
))
lleCompSide = lleSideResult$Y

kmeansLLESide = kmeans(lleCompSide, centers = 3)
dfLLESide = data.frame("Clusters" = kmeansLLESide$cluster-1, "CDR" = patientInfo$cdr)
kmeansSide3LLE = kable(table(dfLLESide), format = "latex", 
                   col.names = c("Cluster","CDR = 0", "CDR = 0.5", "CDR = 1"),
                   booktabs = TRUE)

kmeansLLE2Side = kmeans(lleCompSide, centers = 2)
dfLLE2Side = data.frame("Clusters" = kmeansLLE2Side$cluster-1, "CDR" = patientInfo$cdr)
kmeans2LLESide = kable(table(dfLLE2Side), format = "latex", 
                   col.names = c("Cluster","CDR = 0", "CDR = 0.5", "CDR = 1"), 
                   booktabs = TRUE)

optLLESide = optics(lleCompSide, minPts = 50)
png("LLESideReachability.png")
plot(optLLESide, main = "Reachbility plot for LLE DBScan", cex.main = 0.8)
dev.off()

dbscanLLESide = extractDBSCAN(optLLESide, eps_cl = 10.2)
LLEDBScanDFSide = data.frame("Clusters" = dbscanLLESide$cluster, "CDR" = patientInfo$cdr)
DBScanLLESide = kable(table(LLEDBScanDFSide), format = "latex", 
                   col.names = c("Cluster", "CDR = 0", "CDR = 0.5", "CDR = 1"),
                   booktabs = TRUE)

LLESideTable = c(
  "\\begin{table}[h] \\centering",
  "\\begin{minipage}{0.3\\textwidth}",
  kmeansSide3LLE,        # KMeans Clustering with 3 Clusters
  "\\caption{K-Means Clustering with 3 Clusters for LLE on Side MRI Scans}",
  "\\end{minipage}",
  "\\hspace{3cm}",    # Space between tables
  "\\begin{minipage}{0.3\\textwidth}",
  kmeans2LLESide,        # KMeans Clustering with 2 Clusters
  "\\caption{K-Means Clustering with 2 Clusters for LLE on Side MRI Scans}",
  "\\end{minipage}",
  "\\hspace{3cm}",    # Space between tables
  "\\begin{minipage}{0.3\\textwidth}",
  DBScanLLESide,        # DBScan Clustering
  "\\caption{DBScan Clustering for LLE on Side MRI Scans}",
  "\\end{minipage}",
  "\\end{table}"
)

writeLines(LLESideTable, "LLE_Side_clustering_tables.tex")

```

```{r autoencoder, echo = FALSE, fig.height=4, fig.width=4, results='asis', include = FALSE, eval = TRUE}
# Auto Encoder for Front Scans
 
modelFront = keras_model_sequential() %>% 
  layer_dense(units = 2056, activation = "linear", input_shape = ncol(flatFront)) %>% 
  layer_dense(units = 1024, activation = "sigmoid") %>% 
  layer_dense(units = 128, activation = "sigmoid", name = "bottleneck") %>% 
  layer_dense(units = 1024, activation = "sigmoid") %>% 
  layer_dense(units = 2056, activation = "linear") %>% 
  layer_dense(units = ncol(flatFront))

modelFront %>% compile(
  loss = "mse", 
  optimizer = "adam"
)
invisible(capture.output(
  modelFront %>% fit(x = flatFront, 
                y = flatFront, 
                epochs = 25, 
                batch_size = 128, 
                validation_split = 0.2, 
                verbose = 0)
))

mseFrontAE = evaluate(modelFront, flatFront, flatFront)

modelFront2 = keras_model_sequential() %>% 
  layer_dense(units = 2056, activation = "relu", input_shape = ncol(flatFront)) %>% 
  layer_dense(units = 1024, activation = "relu") %>% 
  layer_dense(units = 128, activation = "relu", name = "bottleneck") %>% 
  layer_dense(units = 1024, activation = "relu") %>% 
  layer_dense(units = 2056, activation = "relu") %>% 
  layer_dense(units = ncol(flatFront))

modelFront2 %>% compile(
  loss = "mse", 
  optimizer = "adam"
)

modelFront2 %>% fit(x = flatFront, 
                   y = flatFront, 
                   epochs = 25, 
                   batch_size = 128, 
                   validation_split = 0.2, 
                   verbose = 0)

mseFrontAE2 = evaluate(modelFront2, flatFront, flatFront)

intermediateLayerFront = keras_model(inputs = modelFront2$input, 
                                     outputs = get_layer(modelFront2, "bottleneck")$output)

intermediateOutputFront = predict(intermediateLayerFront, flatFront)

autoEncFrontKmeans = kmeans(intermediateOutputFront, centers = 3)

AutoEncFrontDF = data.frame("clusters" = autoEncFrontKmeans$cluster-1, "cdr" = patientInfo$cdr)

mseFrontAEDF = data.frame("Linear+Sigmoid" = mseFrontAE, "ReLu" = mseFrontAE2)

kmeans3AEFront = kable(table(AutoEncFrontDF), format = "latex", 
                   col.names = c("Cluster", "CDR = 0", "CDR = 0.5", "CDR = 1"),
                   booktabs = TRUE)

autoEncFrontKmeans2 = kmeans(intermediateOutputFront, centers = 2)

AutoEncFrontDF2 = data.frame("clusters" = autoEncFrontKmeans2$cluster-1, "cdr" = patientInfo$cdr)
kmeans2AEFront = kable(table(AutoEncFrontDF2), format = "latex", 
                   col.names = c("Cluster", "CDR = 0", "CDR = 0.5", "CDR = 1"),
                   booktabs = TRUE)

optFrontAE = optics(intermediateOutputFront, minPts = 50)
png("AEFrontReachability.png")
plot(optFrontAE, main = "Reachbility plot for Auto Encoder with Front MRI Scans DBScan", cex.main = 0.8)
dev.off()

dbscanFrontAE = extractDBSCAN(optFrontAE, eps_cl = 0.0012)
AEFrontDBScanDF = data.frame("clusters" = dbscanFrontAE$cluster, "cdr" = patientInfo$cdr)
DBScanAEFront = kable(table(AEFrontDBScanDF), format = "latex", 
                   col.names = c("Cluster", "CDR = 0", "CDR = 0.5", "CDR = 1"),
                   booktabs = TRUE)

AEFrontTable = c(
  "\\begin{table}[h] \\centering",
  "\\begin{minipage}{0.3\\textwidth}",
  kmeans3AEFront,        # KMeans Clustering with 3 Clusters
  "\\caption{K-Means Clustering with 3 Clusters for AutoEncoder on Front MRI Scans}",
  "\\end{minipage}",
  "\\hspace{3cm}",    # Space between tables
  "\\begin{minipage}{0.3\\textwidth}",
  kmeans2AEFront,        # KMeans Clustering with 2 Clusters
  "\\caption{K-Means Clustering with 2 Clusters for AutoEncoder on Front MRI Scans}",
  "\\end{minipage}",
  "\\hspace{3cm}",    # Space between tables
  "\\begin{minipage}{0.3\\textwidth}",
  DBScanAEFront,        # DBScan Clustering
  "\\caption{DBScan Clustering for AutoEncoder on Front MRI Scans}",
  "\\end{minipage}",
  "\\end{table}"
)

writeLines(AEFrontTable, "AEFront.tex")
```

```{r topAutoEncoder, echo = FALSE, fig.height=4, fig.width=4, results='asis', include = FALSE, eval = TRUE}
# Auto Encoder for Top Scans
 
modelTop = keras_model_sequential() %>% 
  layer_dense(units = 2056, activation = "linear", input_shape = ncol(flatTop)) %>% 
  layer_dense(units = 1024, activation = "sigmoid") %>% 
  layer_dense(units = 128, activation = "sigmoid", name = "bottleneck") %>% 
  layer_dense(units = 1024, activation = "sigmoid") %>% 
  layer_dense(units = 2056, activation = "linear") %>% 
  layer_dense(units = ncol(flatTop))

modelTop %>% compile(
  loss = "mse", 
  optimizer = "adam"
)
invisible(capture.output(
  modelTop %>% fit(x = flatTop, 
                     y = flatTop, 
                     epochs = 25, 
                     batch_size = 128, 
                     validation_split = 0.2, 
                     verbose = 0)
))

mseTopAE = evaluate(modelTop, flatTop, flatTop)

modelTop2 = keras_model_sequential() %>% 
  layer_dense(units = 2056, activation = "relu", input_shape = ncol(flatTop)) %>% 
  layer_dense(units = 1024, activation = "relu") %>% 
  layer_dense(units = 128, activation = "relu", name = "bottleneck") %>% 
  layer_dense(units = 1024, activation = "relu") %>% 
  layer_dense(units = 2056, activation = "relu") %>% 
  layer_dense(units = ncol(flatTop))

modelTop2 %>% compile(
  loss = "mse", 
  optimizer = "adam"
)

modelTop2 %>% fit(x = flatTop, 
                 y = flatTop, 
                 epochs = 25, 
                 batch_size = 128, 
                 validation_split = 0.2, 
                 verbose = 0)

mseTopAE2 = evaluate(modelTop2, flatTop, flatTop)


intermediateLayerTop = keras_model(inputs = modelTop2$input, 
                                     outputs = get_layer(modelTop2, "bottleneck")$output)

intermediateOutputTop = predict(intermediateLayerTop, flatTop)

autoEncTopKmeans = kmeans(intermediateOutputTop, centers = 3)

AutoEncTopDF = data.frame("clusters" = autoEncTopKmeans$cluster-1, "cdr" = patientInfo$cdr)
kmeans3AETop = kable(table(AutoEncTopDF), format = "latex", 
                   col.names = c("Cluster","CDR = 0", "CDR = 0.5", "CDR = 1"), 
                   booktabs = TRUE)

autoEncTopKmeans2 = kmeans(intermediateOutputTop, centers = 2)

AutoEncTopDF2 = data.frame("clusters" = autoEncTopKmeans2$cluster-1, "cdr" = patientInfo$cdr)
kmeans2AETop = kable(table(AutoEncTopDF2), format = "latex", 
                   col.names = c("Cluster","CDR = 0", "CDR = 0.5", "CDR = 1"), 
                   booktabs = TRUE)

optTopAE = optics(intermediateOutputTop, minPts = 50)
png("AETopReachability.png")
plot(optTopAE, main = "Reachbility plot for Auto Encoder with Top MRI Scans DBScan", cex.main = 0.8)
dev.off()
dbscanTopAE = extractDBSCAN(optTopAE, eps_cl = 0.0008)
AETopDBScanDF = data.frame("clusters" = dbscanTopAE$cluster, "cdr" = patientInfo$cdr)
DBScanAETop = kable(table(AETopDBScanDF), format = "latex", 
                   col.names = c("Cluster","CDR = 0", "CDR = 0.5", "CDR = 1"), 
                   booktabs = TRUE)

mseTopAEDF = data.frame("Linear+Sigmoid" = mseTopAE, "ReLu" = mseTopAE2)

AETopTable = c(
  "\\begin{table}[h] \\centering",
  "\\begin{minipage}{0.3\\textwidth}",
  kmeans3AETop,        # KMeans Clustering with 3 Clusters
  "\\caption{K-Means Clustering with 3 Clusters for AutoEncoder on Top MRI Scans}",
  "\\end{minipage}",
  "\\hspace{3cm}",    # Space between tables
  "\\begin{minipage}{0.3\\textwidth}",
  kmeans2AETop,        # KMeans Clustering with 2 Clusters
  "\\caption{K-Means Clustering with 2 Clusters for AutoEncoder on Top MRI Scans}",
  "\\end{minipage}",
  "\\hspace{3cm}",    # Space between tables
  "\\begin{minipage}{0.3\\textwidth}",
  DBScanAETop,        # DBScan Clustering
  "\\caption{DBScan Clustering for AutoEncoder on Top MRI Scans}",
  "\\end{minipage}",
  "\\end{table}"
)

writeLines(AETopTable, "AETopTable.tex")
```

```{r sideAutoEncoder, echo = FALSE, fig.height=4, fig.width=4, results='asis', include = FALSE, eval = TRUE }
# Auto Encoder for Side Scans
 
modelSide = keras_model_sequential() %>% 
  layer_dense(units = 2056, activation = "linear", input_shape = ncol(flatSide)) %>% 
  layer_dense(units = 1024, activation = "sigmoid") %>% 
  layer_dense(units = 128, activation = "sigmoid", name = "bottleneck") %>% 
  layer_dense(units = 1024, activation = "sigmoid") %>% 
  layer_dense(units = 2056, activation = "linear") %>% 
  layer_dense(units = ncol(flatSide))

modelSide %>% compile(
  loss = "mse", 
  optimizer = "adam"
)
invisible(capture.output(
  modelSide %>% fit(x = flatSide, 
                     y = flatSide, 
                     epochs = 25, 
                     batch_size = 128, 
                     validation_split = 0.2, 
                     verbose = 0)
))

mseSideAE = evaluate(modelSide, flatSide, flatSide)


modelSide2 = keras_model_sequential() %>% 
  layer_dense(units = 2056, activation = "relu", input_shape = ncol(flatSide)) %>% 
  layer_dense(units = 1024, activation = "relu") %>% 
  layer_dense(units = 128, activation = "relu", name = "bottleneck") %>% 
  layer_dense(units = 1024, activation = "relu") %>% 
  layer_dense(units = 2056, activation = "relu") %>% 
  layer_dense(units = ncol(flatSide))

modelSide2 %>% compile(
  loss = "mse", 
  optimizer = "adam"
)

modelSide2 %>% fit(x = flatSide, 
                  y = flatSide, 
                  epochs = 25, 
                  batch_size = 128, 
                  validation_split = 0.2, 
                  verbose = 0)

mseSideAE2 = evaluate(modelSide2, flatSide, flatSide)

intermediateLayerSide = keras_model(inputs = modelSide2$input, 
                                     outputs = get_layer(modelSide2, "bottleneck")$output)

intermediateOutputSide = predict(intermediateLayerSide, flatSide)

autoEncKSidemeans = kmeans(intermediateOutputSide, centers = 3)

AutoEncSideDF = data.frame("clusters" = autoEncKSidemeans$cluster-1, "cdr" = patientInfo$cdr)
kmeans3AESide = kable(table(AutoEncSideDF), format = "latex", 
                   col.names = c("Cluster","CDR = 0", "CDR = 0.5", "CDR = 1"), 
                   booktabs = TRUE)

autoEncKSidemeans2 = kmeans(intermediateOutputSide, centers = 2)

AutoEncSideDF2 = data.frame("clusters" = autoEncKSidemeans2$cluster-1, "cdr" = patientInfo$cdr)
kmeans2AESide = kable(table(AutoEncSideDF2), format = "latex", 
                   col.names = c("Cluster","CDR = 0", "CDR = 0.5", "CDR = 1"), 
                   booktabs = TRUE)

optSideAE = optics(intermediateOutputSide, minPts = 50)
png("AESideReachability.png")
plot(optSideAE, main = "Reachbility plot for Auto Encoder with Side MRI Scans DBScan", cex.main = 0.8)
dev.off()
dbscanSideAE = extractDBSCAN(optSideAE, eps_cl = 0.0004)
AESideDBScanDF = data.frame("clusters" = dbscanSideAE$cluster, "cdr" = patientInfo$cdr)
DBScanAESide = kable(table(AESideDBScanDF), format = "latex", 
                   col.names = c("Cluster","CDR = 0", "CDR = 0.5", "CDR = 1"), 
                   booktabs = TRUE)

mseSideAEDF = data.frame("Linear+Sigmoid" = mseSideAE, "ReLu" = mseSideAE2)

AESideTable = c(
  "\\begin{table}[h] \\centering",
  "\\begin{minipage}{0.3\\textwidth}",
  kmeans3AESide,        # KMeans Clustering with 3 Clusters
  "\\caption{K-Means Clustering with 3 Clusters for AutoEncoder on Side MRI Scans}",
  "\\end{minipage}",
  "\\hspace{3cm}",    # Space between tables
  "\\begin{minipage}{0.3\\textwidth}",
  kmeans2AESide,        # KMeans Clustering with 2 Clusters
  "\\caption{K-Means Clustering with 2 Clusters for AutoEncoder on Side MRI Scans}",
  "\\end{minipage}",
  "\\hspace{3cm}",    # Space between tables
  "\\begin{minipage}{0.3\\textwidth}",
  DBScanAESide,        # DBScan Clustering
  "\\caption{DBScan Clustering for AutoEncoder on Side MRI Scans}",
  "\\end{minipage}",
  "\\end{table}"
)

writeLines(AESideTable, "AESideTable.tex")

```

```{r convolutionFront, echo = FALSE, fig.height=4, fig.width=4, results='asis', include = FALSE, eval = FALSE}

# Convolution for Front Scan
numImages = nrow(flatFront)
imgFrontHeight = dim(pixelsMatrix$image_0001_front)[1]
imgFrontWidth = dim(pixelsMatrix$image_0001_front)[2]

flatFrontReshaped = array(flatFront, dim = c(numImages, imgFrontHeight, imgFrontWidth, 1))
flatFrontReshaped = aperm(flatFrontReshaped, c(1, 3, 2, 4), resize = FALSE)

# datagenFront = image_data_generator(
#   rotation_range = 20,
#   width_shift_range = 0.2,
#   height_shift_range = 0.2,
#   shear_range = 0.2,
#   zoom_range = 0.2,
#   horizontal_flip = TRUE,
#   fill_mode = "nearest", 
#   validation_split = 0.2
# )
# 
# train_generatorFront = flow_images_from_data(
#   x = flatFrontReshaped,
#   y = patientInfo$cdr,
#   generator = datagenFront,
#   batch_size = 16,
#   subset = "training"  
# )
# 
# 
# valid_generatorFront = flow_images_from_data(
#   x = flatFrontReshaped,
#   y = patientInfo$cdr,
#   generator = datagenFront,
#   batch_size = 16,
#   subset = "validation" 
# )

input_layerFront = layer_input(shape = c(imgFrontHeight, imgFrontWidth, 1))

Branch1Front = input_layerFront %>% 
  layer_conv_2d(filters = 64, kernel_size = c(3, 3), activation = "relu", padding = "same") %>%
  #layer_conv_2d(filters = 64, kernel_size = c(3, 3), activation = "relu", padding = "same") %>%  
  layer_max_pooling_2d(pool_size = c(2, 2))

Branch2Front = input_layerFront %>% 
  layer_conv_2d(filters = 64, kernel_size = c(5, 5), activation = "relu", padding = "same") %>% 
  #layer_conv_2d(filters = 64, kernel_size = c(5, 5), activation = "relu", padding = "same") %>%  
  layer_max_pooling_2d(pool_size = c(2, 2))

Branch3Front = input_layerFront %>% 
  layer_conv_2d(filters = 64, kernel_size = c(7, 7), activation = "relu", padding = "same") %>% 
  #layer_conv_2d(filters = 64, kernel_size = c(7, 7), activation = "relu", padding = "same") %>%  
  layer_max_pooling_2d(pool_size = c(2, 2))

# Branch4Front = input_layerFront %>%
#   layer_conv_2d(filters = 64, kernel_size = c(9, 9), activation = "relu", padding = "same") %>%
#   layer_conv_2d(filters = 64, kernel_size = c(9, 9), activation = "relu", padding = "same") %>%
#   layer_max_pooling_2d(pool_size = c(2, 2))
# 
# Branch5Front = input_layerFront %>%
#   layer_conv_2d(filters = 64, kernel_size = c(11, 11), activation = "relu", padding = "same") %>%
#   layer_conv_2d(filters = 64, kernel_size = c(11, 11), activation = "relu", padding = "same") %>%
#   layer_max_pooling_2d(pool_size = c(2, 2))

merged = layer_concatenate(list(Branch1Front, Branch2Front, Branch3Front))

outputFront = merged %>% 
  layer_flatten() %>% 
  layer_dense(units = 128, activation = "relu") %>% 
  layer_dropout(rate = 0.5) %>% 
  layer_dense(units = 64, activation = "relu") %>% 
  layer_dropout(rate = 0.5) %>% 
  layer_dense(units = 3, activation = "softmax")

multiBranchCNNFront = keras_model(inputs = input_layerFront, outputs = outputFront)

# class_weights = list(
#   "0" = 1,
#   "0.5" = sum(patientInfo$cdr == 0) / sum(patientInfo$cdr == 0.5),
#   "1" = sum(patientInfo$cdr == 0) / sum(patientInfo$cdr == 1)
# )

multiBranchCNNFront %>% compile(
  loss = "sparse_categorical_crossentropy", 
  optimizer = "adam", 
  metrics = c("accuracy")
)

multiBranchCNNFront %>% fit(x = flatFrontReshaped,
                            y = patientInfo$cdr,
                            epochs = 50,
                            batch_size = 128, 
                            validation_split = 0.2, 
                            verbose = 0)

mseFConv = evaluate(multiBranchCNNFront, flatFrontReshaped, patientInfo$cdr)
mseFConv

predictionsFront = multiBranchCNNFront %>% predict(flatFrontReshaped)

predictionsClassFront = apply(predictionsFront, 1, which.max) - 1

ConvFrontAE = kable(data.frame("Loss" = mseFConv["loss"], "Accuracy" = mseFConv["accuracy"]), format = "latex",
                   booktabs = TRUE)

misclassifiedFront = which(predictionsClassFront != patientInfo$cdr)

ConvFrontMisClassDF = data.frame(
  "CDR 0" = sum(patientInfo$cdr[misclassifiedFront] == 0),
  "CDR 0.5" = sum(patientInfo$cdr[misclassifiedFront] == 0.5),
  "CDR 1" = sum(patientInfo$cdr[misclassifiedFront] == 1)
)

ConvFrontMisClass = kable(ConvFrontMisClassDF, format = "latex", booktabs = TRUE)

ConvFrontTable = c(
  "\\begin{table}[h] \\centering",
  "\\begin{minipage}{0.3\\textwidth}",
  ConvFrontAE,        
  "\\caption{Error and Accuracy for Convolution on Front Scans}",
  "\\end{minipage}",
  "\\hspace{3cm}",    # Space between tables
  "\\begin{minipage}{0.3\\textwidth}",
  ConvFrontMisClass,        # KMeans Clustering with 2 Clusters
  "\\caption{Frequency of CDR levels that were misclassified for Front Scans}",
  "\\end{minipage}",
  "\\end{table}"
)

writeLines(ConvFrontTable, "ConvFront.tex")

```

```{r convTopScan, echo = FALSE, fig.height=4, fig.width=4, results='asis', include = FALSE, eval = FALSE}

# Convolution for Top Scan
 
numImages = nrow(flatTop)
imgTopHeight = dim(pixelsMatrix$image_0001_top)[1]
imgTopWidth = dim(pixelsMatrix$image_0001_top)[2]

flatTopReshaped = array(flatTop, dim = c(numImages, imgTopHeight, imgTopWidth, 1))
# flatTopReshaped = aperm(flatTopReshaped, c(1, 3, 2, 4), resize = FALSE)

# datagenTop = image_data_generator(
#   rotation_range = 20,
#   width_shift_range = 0.05,
#   height_shift_range = 0.05,
#   shear_range = 0.1,
#   zoom_range = 0.1,
#   horizontal_flip = TRUE, 
#   fill_mode = "nearest", 
#   validation_split = 0.2
# )
# 
# train_generatorTop = flow_images_from_data(
#   x = flatTopReshaped,
#   y = patientInfo$cdr,
#   generator = datagenTop,
#   batch_size = 16,
#   subset = "training"  
# )
# 
# 
# valid_generatorTop = flow_images_from_data(
#   x = flatTopReshaped,
#   y = patientInfo$cdr,
#   generator = datagenTop,
#   batch_size = 16,
#   subset = "validation" 
# )

input_layerTop = layer_input(shape = c(imgTopHeight, imgTopWidth, 1))

Branch1Top = input_layerTop %>% 
  layer_conv_2d(filters = 64, kernel_size = c(3, 3), activation = "relu", padding = "same") %>%
  #layer_conv_2d(filters = 64, kernel_size = c(3, 3), activation = "relu", padding = "same") %>%  
  layer_max_pooling_2d(pool_size = c(2, 2))

Branch2Top = input_layerTop %>% 
  layer_conv_2d(filters = 64, kernel_size = c(5, 5), activation = "relu", padding = "same") %>% 
  #layer_conv_2d(filters = 64, kernel_size = c(5, 5), activation = "relu", padding = "same") %>%  
  layer_max_pooling_2d(pool_size = c(2, 2))

Branch3Top = input_layerTop %>% 
  layer_conv_2d(filters = 64, kernel_size = c(7, 7), activation = "relu", padding = "same") %>% 
  #layer_conv_2d(filters = 64, kernel_size = c(7, 7), activation = "relu", padding = "same") %>%  
  layer_max_pooling_2d(pool_size = c(2, 2))

# Branch4Top = input_layerTop %>% 
#   layer_conv_2d(filters = 64, kernel_size = c(9, 9), activation = "relu", padding = "same") %>% 
#   layer_conv_2d(filters = 64, kernel_size = c(9, 9), activation = "relu", padding = "same") %>%  
#   layer_max_pooling_2d(pool_size = c(2, 2))
# 
# Branch5Top = input_layerTop %>% 
#   layer_conv_2d(filters = 64, kernel_size = c(11, 11), activation = "relu", padding = "same") %>% 
#   layer_conv_2d(filters = 64, kernel_size = c(11, 11), activation = "relu", padding = "same") %>%  
#   layer_max_pooling_2d(pool_size = c(2, 2))

mergedTop = layer_concatenate(list(Branch1Top, Branch2Top, Branch3Top))

outputTop = mergedTop %>% 
  layer_flatten() %>% 
  layer_dense(units = 128, activation = "relu") %>% 
  layer_dropout(rate = 0.5) %>% 
  layer_dense(units = 64, activation = "relu") %>% 
  layer_dropout(rate = 0.5) %>% 
  layer_dense(units = 3, activation = "softmax")

multiBranchCNNTop = keras_model(inputs = input_layerTop, outputs = outputTop)

multiBranchCNNTop %>% compile(
  loss = "sparse_categorical_crossentropy", 
  optimizer = "adam", 
  metrics = c("accuracy")
)

multiBranchCNNTop %>% fit(x = flatTopReshaped,
                          y = patientInfo$cdr,
                          epochs = 50,
                          batch_size = 128, 
                          validation_split = 0.2, 
                          verbose = 0)

mseTConv = evaluate(multiBranchCNNTop, flatTopReshaped, patientInfo$cdr)
mseTConv

predictionsTop = multiBranchCNNTop %>% predict(flatTopReshaped)

predictionsClassTop = apply(predictionsTop, 1, which.max) - 1

misclassifiedTop = which(predictionsClassTop != patientInfo$cdr)

ConvTopAE = kable(data.frame("Loss" = mseTConv["loss"], "Accuracy" = mseTConv["accuracy"]), format = "latex",
                   booktabs = TRUE)


convTopMisClassDF = data.frame(
  "CDR 0" = sum(patientInfo$cdr[misclassifiedTop] == 0),
  "CDR 0.5" = sum(patientInfo$cdr[misclassifiedTop] == 0.5),
  "CDR 1" = sum(patientInfo$cdr[misclassifiedTop] == 1)
)

ConvTopMisClass = kable(convTopMisClassDF, format = "latex", booktabs = TRUE)

ConvTopTable = c(
  "\\begin{table}[h] \\centering",
  "\\begin{minipage}{0.3\\textwidth}",
  ConvTopAE,  
  "\\caption{Error and Accuracy for Convolution on Top Scans}",
  "\\end{minipage}",
  "\\hspace{3cm}",    # Space between tables
  "\\begin{minipage}{0.3\\textwidth}",
  ConvTopMisClass,        # KMeans Clustering with 2 Clusters
  "\\caption{Frequency of CDR levels that were misclassified for Top Scans}",
  "\\end{minipage}",
  "\\end{table}"
)

writeLines(ConvTopTable, "ConvTop.tex")

```

```{r convSideScan, echo = FALSE, fig.height=4, fig.width=4, results='asis', include = FALSE, eval = FALSE}
# Convolution for Side Scan
 
numImages = nrow(flatSide)
imgSideHeight = dim(pixelsMatrix$image_0001_side)[1]
imgSideWidth = dim(pixelsMatrix$image_0001_side)[2]

sideMatrix = matrix(flatSide, nrow = numImages, byrow = FALSE)

flatSideReshaped = array(sideMatrix, dim = c(numImages, imgSideHeight, imgSideWidth, 1))
#flatSideReshaped = aperm(flatSideReshaped, c(1, 3, 2, 4))

# identical(t(flatSideReshaped[1,,,]), pixelsMatrix$image_0001_side)

# datagenSide = image_data_generator(
#   rotation_range = 20,
#   width_shift_range = 0.05,
#   height_shift_range = 0.05,
#   shear_range = 0.1,
#   zoom_range = 0.1,
#   horizontal_flip = TRUE,
#   fill_mode = "nearest", 
#   validation_split = 0.2
# )
# 
# train_generatorSide = flow_images_from_data(
#   x = flatSideReshaped,
#   y = patientInfo$cdr,
#   generator = datagenSide,
#   batch_size = 16,
#   subset = "training"  
# )
# 
# 
# valid_generatorSide = flow_images_from_data(
#   x = flatSideReshaped,
#   y = patientInfo$cdr,
#   generator = datagenSide,
#   batch_size = 16,
#   subset = "validation" 
# )

input_layerSide = layer_input(shape = c(imgSideHeight, imgSideWidth, 1))

Branch1Side = input_layerSide %>% 
  layer_conv_2d(filters = 64, kernel_size = c(3, 3), activation = "relu", padding = "same") %>%
  #layer_conv_2d(filters = 64, kernel_size = c(3, 3), activation = "relu", padding = "same") %>%  
  layer_max_pooling_2d(pool_size = c(2, 2))

Branch2Side = input_layerSide %>% 
  layer_conv_2d(filters = 64, kernel_size = c(5, 5), activation = "relu", padding = "same") %>% 
  #layer_conv_2d(filters = 64, kernel_size = c(5, 5), activation = "relu", padding = "same") %>%  
  layer_max_pooling_2d(pool_size = c(2, 2))

Branch3Side = input_layerSide %>% 
  layer_conv_2d(filters = 64, kernel_size = c(7, 7), activation = "relu", padding = "same") %>% 
  #layer_conv_2d(filters = 64, kernel_size = c(7, 7), activation = "relu", padding = "same") %>%  
  layer_max_pooling_2d(pool_size = c(2, 2))

# Branch4Side = input_layerSide %>% 
#   layer_conv_2d(filters = 64, kernel_size = c(9, 9), activation = "relu", padding = "same") %>% 
#   layer_batch_normalization() %>%
#   layer_conv_2d(filters = 64, kernel_size = c(9, 9), activation = "relu", padding = "same") %>%  
#   layer_max_pooling_2d(pool_size = c(2, 2))
# 
# Branch5Side = input_layerSide %>% 
#   layer_conv_2d(filters = 64, kernel_size = c(11, 11), activation = "relu", padding = "same") %>% 
#   layer_batch_normalization() %>%
#   layer_conv_2d(filters = 64, kernel_size = c(11, 11), activation = "relu", padding = "same") %>%  
#   layer_max_pooling_2d(pool_size = c(2, 2))

mergedSide = layer_concatenate(list(Branch1Side, Branch2Side, Branch3Side))

outputSide = mergedSide %>% 
  layer_flatten() %>% 
  layer_dense(units = 128, activation = "relu") %>% 
  layer_dropout(rate = 0.5) %>% 
  layer_dense(units = 64, activation = "relu") %>% 
  layer_dropout(rate = 0.5) %>% 
  layer_dense(units = 3, activation = "softmax")

multiBranchCNNSide = keras_model(inputs = input_layerSide, outputs = outputSide)

multiBranchCNNSide %>% compile(
  loss = "sparse_categorical_crossentropy", 
  optimizer = "adam", 
  metrics = c("accuracy")
)

multiBranchCNNSide %>% fit(x = flatSideReshaped,
                           y = patientInfo$cdr,
                           epochs = 50,
                          batch_size = 128, 
                          validation_split = 0.2, 
                          verbose = 0)

mseSConv = evaluate(multiBranchCNNSide, flatSideReshaped, patientInfo$cdr)
mseSConv

predictionsSide = multiBranchCNNSide %>% predict(flatSideReshaped)

predictionsClassSide = apply(predictionsSide, 1, which.max) - 1

misclassifiedSide = which(predictionsClassSide != patientInfo$cdr)


ConvSideAE = kable(data.frame("Loss" = mseSConv["loss"], "Accuracy" = mseSConv["accuracy"]), format = "latex",
                   booktabs = TRUE)

convSideMisClassDF = data.frame(
  "CDR 0" = sum(patientInfo$cdr[misclassifiedSide] == 0),
  "CDR 0.5" = sum(patientInfo$cdr[misclassifiedSide] == 0.5),
  "CDR 1" = sum(patientInfo$cdr[misclassifiedSide] == 1)
)

ConvSideMisClass = kable(convSideMisClassDF, format = "latex", booktabs = TRUE)


ConvSideTable = c(
  "\\begin{table}[h] \\centering",
  "\\begin{minipage}{0.3\\textwidth}",
  ConvSideAE, 
  "\\caption{Error and Accuracy for Convolution on Side Scans}",
  "\\end{minipage}",
  "\\hspace{3cm}",    # Space between tables
  "\\begin{minipage}{0.3\\textwidth}",
  ConvSideMisClass,        # KMeans Clustering with 2 Clusters
  "\\caption{Frequency of CDR levels that were misclassified for Side Scans}",
  "\\end{minipage}",
  "\\end{table}"
)

writeLines(ConvSideTable, "ConvSide.tex")

```

# 5: Results

## 5.1: LLE on Front MRI Scans

\input{LLE_Front_clustering_tables.tex}

\newpage 
## 5.2: LLE on Top MRI Scans

\input{LLE_Top_clustering_tables.tex}

## 5.3: LLE on Side MRI Scans

\input{LLE_Side_clustering_tables.tex}

Can see from the tables that the clusters are not able to differentiate between different levels of CDR after performing dimension reduction using LLE. The CDR levels just seem to be divided between each cluster somewhat equally, with 1 cluster sometimes taking the majority of the points. The LLE used 30 neighbors and 80 dimensions, with 30 neighbors being usual for image MRI classification and 80 dimensions being chosen from the cumulative variance plot of PCA. DBScan used an epsilon of 10 for all 3 scans, which was based on the reachability plot in the appendix. 

\newpage

## 5.4: Auto Encoder on Front MRI Scans

\input{AEFront.tex}

## 5.5: Auto Encoder on Top MRI Scans

\input{AETopTable.tex}

\newpage

## 5.6: Auto Encoder on Side MRI Scans

\input{AESideTable.tex}

Can see the same result as with LLE for Auto Encoders. The Auto Encoder does not appear to be able to learn the patterns of the brain at a sufficiently low level and so the cluster assignments do not show any patterns. 

Sigmoid with linear and relu were the 2 models that provided the lowest MSE and thus those were chosen. Relu gave the lowest of the 2 and thus was used for all 3 different scans, based on the tables from the appendix. The bottleneck being 128 was chosen for computational efficiency as well as it being commonly used size for images when being reduced. The epsilon for DBScan was 0.0005 for front scans, 0.0004 for top scans and 0.0006 for side scans based on the reachability plots in the appendix. 

These results vary due to the gradient descent method being dependent on the starting value. 

## 5.7: CNN on Front MRI Scans

\input{ConvFront.tex}

## 5.8: CNN on Top MRI Scans

\input{ConvTop.tex}

\newpage

## 5.9: CNN on Side MRI Scans

\input{ConvSide.tex}

The CNN does provide better results, with the front and side scan having between a 65% - 70% accuracy from running the result many times which can be difficult to show due to the randomness of the results when re running the CNN. Top scans performed slightly worse generally. Due to computing power restrictions, I was not able to show the complete tuning process, but generating more images using rotations, flips, zooms etc resulted in the network becoming biased. Too many images with CDR = 0 were created and so when fitting the network it assigned all images a CDR of 0. While the CNN did perform better than the other techniques used, the CNN that I was able to use was limited severely by my computing power as 64 filters with 3 branches was the maximum feasible network that was runnable.

The CNN struggles mostly with classifying MRI scans with a CDR level of 0.5, this is likely due to the difference between MRI scans with 0 and 0.5 as well as MRI scans with 0.5 and 1 being difficult to differentiate between with an insufficiently deep model, however the CNN was able to differentiate between MRI scans with CDR level of 0 and 1. 

These results vary due to the gradient descent method being dependent on the starting value. 

# 6: Conclusion

From the results, the methods used in this report were unable to confidently detect differences in brain structure for Alzheimers and non-Alzheimers patients when using dimension reduction and clustering techniques. Using just a CNN performed much better and was able to differentiate between no dementia and severe dementia while detecting just mild dementia was slightly more difficult due to the data and processing restrictions. Therefore we can conclude that it is possible to detect Alzheimers through structural differences in the MRI scans of individuals. However, the ability to predict it depends on being able to train sufficiently deep models and having sufficient data to accurately train the model. 

Areas for further research would be the use of Support Vector Machines in MRI structural analysis, as these models have also performed well in previous research, as well as the use of more deep convolutional models with sufficient data to train. Gaussian Mixture Models may also perform better than both K-Means and DBScan due to the ability to work well with non spherical clusters and allowing different points to belong to multiple clusters based on probability which is useful for regions of the brain where there is a gradual change between pixels. 

\newpage
# References

Alzheimer's Association. 2024. *2024 Alzheimer’s disease facts and figures*. Available:<https://www.alz.org/getmedia/76e51bb6-c003-4d84-8019-e0779d8c4e8d/alzheimers-facts-and-figures.pdf>. [2024, 7 March]

Frisoni G., Fox N., Jack C Jr., Scheltens P., Thompson P. 2010. *The clinical use of structural MRI in Alzheimer disease*. Nat Rev Neurol. 6(2):67-77. doi: 10.1038/nrneurol.2009.215.

Mandal, P., Mahato, R. 2023. *Deep Multi-Branch CNN Architecture for Early Alzheimers Detection from Brain MRIs.* doi: 10.3390/s23198192.

Marcus, D, Wang T, Parker J., Csernasky J., Morris J., Buckner R.2007. *Open Accesss Series of Imaging Studies (OASIS): Cross-Sectional MRI Data in Young Middle Aged, Nondemented, and Demented Older Adults*. Journal of Cognitive Neuroscience, 19, 1498 - 1507. doi: 10.1162/jocn.2007.19.9.1498.



\newpage
# Appendix 
```{r autoEncoderNetwork, echo = FALSE, fig.show = "hold", fig.align = "center", out.height = "50%", out.width="60%", fig.cap = "AutoEncoder Network Design", fig.width=6, fig.height=6}
knitr::include_graphics(c("AutoEncoderNetwork.png"))
```

```{r CNNNetwork, echo = FALSE, fig.show = "hold", fig.align = "center", out.height = "50%", out.width="60%", fig.cap = "Convolutional Neural Network Design", fig.width=6, fig.height=6}
knitr::include_graphics(c("CNNNetwork.png"))
```

```{r pcaFront, echo = FALSE, fig.show = "hold", fig.align ="center", fig.cap= "80 principal components explains around 80% of the variance", fig.width=6, fig.height=6}
knitr::include_graphics(c("frontPCA.png"))

``` 

```{r LLEReachability, echo = FALSE, fig.show = "hold", fig.align = "center",fig.cap = "Epsilon = 10 is chosen as the cutoff", fig.width=6, fig.height=6}
knitr::include_graphics(c("LLEReachability.png"))

``` 

```{r pcaTop, echo = FALSE, fig.show = "hold", fig.align = "center", fig.cap = "80 principal components explains around 80% of the variance", fig.width=6, fig.height=6}
knitr::include_graphics(c("topPCA.png"))

``` 

```{r LLETopReachability, echo = FALSE, fig.show = "hold", fig.align = "center",fig.cap = "Epsilon = 10 is chosen as the cutoff", fig.width=6, fig.height=6}

knitr::include_graphics(c("LLETopReachability.png"))

```

```{r pcaSide, echo = FALSE, fig.show = "hold", fig.align = "center", fig.cap= "80 principal components explains around 80% of the variance", fig.width=6, fig.height=6}
knitr::include_graphics(c("sidePCA.png"))

``` 

```{r LLESideReachability, echo = FALSE, fig.show = "hold", fig.align = "center", fig.cap = "Epsilon = 10.2 is chosen as the cutoff"}

knitr::include_graphics(c("LLESideReachability.png"))

```
```{r AeFrontReachability, echo = FALSE, fig.show = "hold", fig.align = "center",fig.cap = "Epsilon = 0.0012 is chosen as the cutoff", fig.width=6, fig.height=6}
knitr::include_graphics(c("AeFrontReachability.png"))
```
```{r AeTopReachability, echo = FALSE, fig.show = "hold", fig.align = "center", fig.cap = "Epsilon = 0.0008 is chosen as the cutoff", fig.width=6, fig.height=6}
knitr::include_graphics(c("AeTopReachability.png"))
```
```{r AeSideReachability, echo = FALSE, fig.show = "hold", fig.align = "center",fig.cap = "Epsilon = 0.0004 is chosen as the cutoff", fig.width=6, fig.height=6}
knitr::include_graphics(c("AeSideReachability.png"))
```
\newpage

```{r MSETables, echo = FALSE}

kable(mseFrontAEDF, caption = "MSE For Auto Encoder for Front Scans")

kable(mseTopAEDF, caption = "MSE For Auto Encoder for Top Scans")

kable(mseSideAEDF, caption = "MSE For Auto Encoder for Side Scans")


```